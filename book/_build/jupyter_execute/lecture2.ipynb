{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e5b12e",
   "metadata": {},
   "source": [
    "# Lecture 2\n",
    "\n",
    "In this lecture we perform  tensor network contraction explicity\n",
    "- {ref}`graphicalcontraction`\n",
    "- {ref}`symboliccontraction`\n",
    "\n",
    "\n",
    "\n",
    "(graphicalcontraction)=\n",
    "## Binary Tensor Contraction - Graphical\n",
    "\n",
    "Contraction algorithmically can be broken down to as series of steps. Lets look at the following example \n",
    "\n",
    "```{image} /images/lecture2fig1.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "\n",
    "### Step 0\n",
    "We first need to initialized the desired tensor. Using Python this is done as\n",
    "#### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7feafdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library that allows us to deal with arrays efficiently\n",
    "import numpy as np\n",
    "\n",
    "d = 2\n",
    "# create two random tensors\n",
    "A_vec = np.random.rand(d,d,d,d)\n",
    "B_vec = np.random.rand(d,d,d,d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbec3c4",
   "metadata": {},
   "source": [
    "where we (as an example) create two random rank-4 tensors. \n",
    "\n",
    "\n",
    "### Step 1\n",
    "We first perform a transposition of the the two tensors A and B in the following way\n",
    "\n",
    "```{image} /images/lecture2fig2.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "where we obtained new A and B that have elements shuffled. The main idea is that need to shuttle (transpose or permute) the target contraction indices for the matrix A to right, while for the B matrix we have to shuttle (transpose or permute) the contraction indices to left.  \n",
    "\n",
    "#### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59efb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose the generate vectors\n",
    "A_vec1 = A_vec.transpose(0,2,1,3)\n",
    "B_vec1 = B_vec.transpose(0,3,1,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8ef03",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "Afterwards we reshape the new A and B tensors in such a way \n",
    "\n",
    "```{image} /images/lecture2fig3.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "Here the idea is that we separate the tensor into a part that we do not touch (indices I and K), and the ones over we operate (index J). By operating we imply performing matrix-matrix multiplication on the targeted indices J.\n",
    "\n",
    "#### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecfa0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the tensors\n",
    "A_vec2 = A_vec1.reshape(d**2,d**2)\n",
    "B_vec2 = B_vec1.reshape(d**2,d**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6af7b0",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "After reshape the indices J have the same dimension and we can perform matrix-matrix multiplication over that index\n",
    "\n",
    "```{image} /images/lecture2fig4.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "\n",
    "#### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b046c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix-matrix multiplication\n",
    "C_prim = A_vec2 @ B_vec2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b5711",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "We do a final reshape of the tensor to the desired number of legs as\n",
    "\n",
    "```{image} /images/lecture2fig5.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "\n",
    "#### Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d910fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.09725572 1.42488522]\n",
      "   [1.37927833 1.33462755]]\n",
      "\n",
      "  [[1.21799203 1.43758697]\n",
      "   [1.14475168 1.14318674]]]\n",
      "\n",
      "\n",
      " [[[1.53658882 1.32085715]\n",
      "   [0.68369798 0.68026999]]\n",
      "\n",
      "  [[1.10235456 0.72067637]\n",
      "   [0.37726278 0.45510506]]]]\n"
     ]
    }
   ],
   "source": [
    "# we need to keep wanted leg number of the tensor\n",
    "C = C_prim.reshape(d,d,d,d)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80798ad9",
   "metadata": {},
   "source": [
    "### Comparison with direct evaluation\n",
    "We can perform the contraction in its full glory, i.e. over all the involved indices as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2b3a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.09725572 1.42488522]\n",
      "   [1.37927833 1.33462755]]\n",
      "\n",
      "  [[1.21799203 1.43758697]\n",
      "   [1.14475168 1.14318674]]]\n",
      "\n",
      "\n",
      " [[[1.53658882 1.32085715]\n",
      "   [0.68369798 0.68026999]]\n",
      "\n",
      "  [[1.10235456 0.72067637]\n",
      "   [0.37726278 0.45510506]]]]\n"
     ]
    }
   ],
   "source": [
    "# define an empty 4-leg tensor\n",
    "C_direct = np.zeros([d,d,d,d])\n",
    "\n",
    "# loop over the indices\n",
    "for i in range(0,d):\n",
    "\tfor j in range(0,d):\n",
    "\t\tfor k in range(0,d):\n",
    "\t\t\tfor l in range(0,d):\n",
    "\n",
    "\t\t\t\t# perform the matrix-matrix multiplication explicitely\n",
    "\t\t\t\tfor m in range(0,d):\n",
    "\t\t\t\t\tfor n in range(0,d):\n",
    "\n",
    "\t\t\t\t\t\tC_direct[i,j,k,l] = C_direct[i,j,k,l] + A_vec[i,m,j,n]*B_vec[m,k,l,n]\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\n",
    "print(C_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e99dd",
   "metadata": {},
   "source": [
    "As we can see the outputs are the same! This implies that binary contraction is well defined and proper algorithmic procedure to perform tensor contraction.\n",
    "\n",
    "```{note}\n",
    "**Exercise1:** Using python function *time* check how the binary tensor network contraction scales with increasing number of local dimension d as compared to the direct approach. Use *matplotlib* to present the scaling plots. \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "(symboliccontraction)=\n",
    "## Binary Tensor Contraction - Symbolic\n",
    "Sometimes it is easier to take care of the indices symbolically rather graphical and the whole process can be represented as \n",
    "\n",
    "\n",
    "```{image} /images/lecture2fig6.png\n",
    ":alt: def\n",
    ":class: bg-primary mb-1\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "The final step is sometimes necessary depending on what kind of contraction and what kind of tensors are used. \n",
    "\n",
    "```{note}\n",
    "**Exercise2:** Try to contract the following tensors A_{ijab} B_{kabl}. Verify that that in this case one has to perform an additional transposition (i.e. step 5) in order to obtain the correct result. \n",
    "\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "source_map": [
   13,
   39,
   48,
   67,
   72,
   90,
   95,
   110,
   114,
   132,
   136,
   141,
   160
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}